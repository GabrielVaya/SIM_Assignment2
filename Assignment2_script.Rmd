---
title: "Untitled"
author: "Gabriel Vay√°"
date: "2023-12-13"
output: 
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

library(car)
library(MASS)
library(missMDA)
library(visdat)
library(FactoMineR)
library(chemometrics)
library(corrplot)
library(naniar)
library(nortest)
library(visdat)
library(tidyverse)
library(lsr)
```

First thing will be to load the data into R, and redeclaring the variables to properly comply with the needs of the analysis. Notice we relable the levels of the variable SeniorCitizen from (0,1) to (No, Yes) for practical reasons. 
```{r}
#setwd("C:\\Users\\darry\\Documents\\MDS\\Statistical_Inference_And_Modelling\\SIM_Assignment2")
setwd("/Users/gabrielvayaabad/Desktop/MDS/SIM/Assignment 2")
df <- read.csv2("WA_Fn-UseC_-Telco-Customer-Churn.csv")

df$MonthlyCharges <- as.numeric(df$MonthlyCharges)
df$TotalCharges <- as.numeric(df$TotalCharges)
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], as.factor)
df$SeniorCitizen <- as.factor(df$SeniorCitizen)
df$customerID <- as.character(df$customerID)
levels(df$SeniorCitizen) <- c("No","Yes")
```


#DataPreparation

#Deduplication
Now we check for duplicates in the dataset, and we see all rows are distinct. 
```{r}
dup <- which(duplicated(df)) #No duplicate rows
```

#Missing Values
For the missing data, we can...
```{r}
vis_miss(df)
df[is.na(df$TotalCharges),] #NAs only found in TotalCharges variable

mcar_test(df) #p-value is 0 -> not random
df$tenure[is.na(df$TotalCharges)] #TotalCharges are NA when tenure is 0
df$TotalCharges[is.na(df$TotalCharges)] <- 0 #impute with 0
```

#Deduplication (again)
```{r}
dup <- which(duplicated(df)) #No duplicate rows
```

#Looking for errors
```{r}
df.aux <- df
df.aux$TheoreticalTotalCharges <- df.aux$tenure*df.aux$MonthlyCharges
df.aux[df.aux$TheoreticalTotalCharges > df.aux$TotalCharges,]
```


#EDA (+ Univariate Outliers)

#gender
```{r}
na.gender <- sum(is.na(df$gender)) #No NAs
barplot(table(df$gender),col='lightblue') #Balanced
```

#SeniorCitizen
```{r}
na.seniorcitizen <- sum(is.na(df$SeniorCitizen)) #No NAs
barplot(table(df$SeniorCitizen),col='lightblue') #Unbalanced
```

#Partner
```{r}
na.partner <- sum(is.na(df$Partner)) #No NAs
barplot(table(df$Partner),col='lightblue') #Balanced
```

#Dependents
```{r}
na.dependents <- sum(is.na(df$Dependents)) #No NAs
barplot(table(df$Dependents),col='lightblue') #Unbalanced
```

#tenure
```{r}
na.tenure <- sum(is.na(df$tenure)) #No NAs
hist(df$tenure,freq=F,15) #Young customers overrepresented
mm <- mean(df$tenure,na.rm=T);ss <- sd(df$tenure,na.rm=T);
curve(dnorm(x,mm,ss),col="red",add=T)
#shapiro.test(df$tenure) #Error: too many samples for shapiro test
ad.test(df$tenure) #Anderson-Darling test: Not normally distributed
Boxplot(df$tenure,range=1.5,id=list(n=Inf,labels=rownames(df))) #No mild univariate outliers
Boxplot(df$tenure,range=3,id=list(n=Inf,labels=rownames(df))) #No extreme univariate outliers
```

#PhoneService
```{r}
na.phoneservice <- sum(is.na(df$PhoneService)) #No NAs
barplot(table(df$PhoneService),col='lightblue') #Unbalanced
```

#MultipleLines
```{r}
na.multiplelines <- sum(is.na(df$MultipleLines)) #No NAs
barplot(table(df$MultipleLines),col='lightblue') #Unbalanced in "No phone service"
```

#InternetService
```{r}
na.internetservice <- sum(is.na(df$InternetService)) #No NAs
barplot(table(df$InternetService),col='lightblue') #Unbalanced
```

#OnlineSecurity
```{r}
no.onlinesecurity <- sum(is.na(df$OnlineSecurity)) #No NAs
barplot(table(df$OnlineSecurity),col='lightblue') #Unbalanced in "No"
```

#OnlineBackup
```{r}
na.onlinebackup <- sum(is.na(df$OnlineBackup)) #No NAs
barplot(table(df$OnlineBackup),col='lightblue') #Unbalanced
```

#DeviceProtection
```{r}
na.deviceprotection <- sum(is.na(df$DeviceProtection)) #No NAs
barplot(table(df$DeviceProtection),col='lightblue') #Unbalanced
```

#TechSupport
```{r}
na.techsupport <- sum(is.na(df$TechSupport)) #No NAs
barplot(table(df$TechSupport),col='lightblue') #Unbalanced in "No"
```

#StreamingMovies
```{r}
na.streamingmovies <- sum(is.na(df$StreamingMovies)) #No NAs
barplot(table(df$StreamingMovies),col='lightblue') #Unbalanced in "No internet service"
```

#Contract
```{r}
na.contract <- sum(is.na(df$Contract)) #No NAs
barplot(table(df$Contract),col='lightblue') #Unbalanced in "Month-to-month"
```

#PaperlessBilling
```{r}
na.paperlessbilling <- sum(is.na(df$PaperlessBilling)) #No NAs
barplot(table(df$PaperlessBilling),col='lightblue') #Relatively balanced
```

#PaymentMethod
```{r}
na.paymentmethod <- sum(is.na(df$PaymentMethod)) #No NAs
barplot(table(df$PaymentMethod),col='lightblue') #Unbalanced in "Credit card (automatic)"
```

#MonthlyCharges
```{r}
na.monthlycharges <- sum(is.na(df$MonthlyCharges)) #No NAs
hist(df$MonthlyCharges,freq=F,15)
mm <- mean(df$MonthlyCharges,na.rm=T)
ss <- sd(df$MonthlyCharges,na.rm=T)
curve(dnorm(x,mm,ss),col="red",add=T)
#shapiro.test(df$MonthlyCharges) #Error: too many samples for shapiro test
ad.test(df$MonthlyCharges) #Anderson-Darling test: Not normally distributed
Boxplot(df$MonthlyCharges,range=1.5,id=list(n=Inf,labels=rownames(df))) #No mild univariate outliers
Boxplot(df$MonthlyCharges,range=3,id=list(n=Inf,labels=rownames(df))) #No severe univariate outliers
```

#TotalCharges
```{r}
na.totalcharges <- sum(is.na(df$TotalCharges)) #11 NAs imputed earlier
hist(df$TotalCharges,freq=F,15)
mm <- mean(df$TotalCharges,na.rm=T)
ss <- sd(df$TotalCharges,na.rm=T)
curve(dnorm(x,mm,ss),col="red",add=T)
#shapiro.test(df$TotalCharges) #Error: too many samples for shapiro test
ad.test(df$TotalCharges) #Anderson-Darling test: Not normally distributed
Boxplot(df$TotalCharges,range=1.5,id=list(n=Inf,labels=rownames(df))) #No mild univariate outliers
Boxplot(df$TotalCharges,range=3,id=list(n=Inf,labels=rownames(df))) #No severe univariate outliers
```

#Target Variable: Churn
```{r}
na.churn <- sum(is.na(df$Churn)) #No NAs
barplot(table(df$Churn),col='lightblue') #Unbalanced
```

#Correlations and Associations
```{r}
# Correlations
vis_dat(df[,num], sort_type = FALSE)
vis_cor(df[,num])

# Mixed Associations (using Chisquared pvalue and CramersV)
cat <- which(sapply(df, function(x) is.factor(x) || is.character(x)))

# function to get chi square p value and Cramers V
f = function(x,y) {
    tbl = df %>% select(x,y) %>% table()
    chisq_pval = round(chisq.test(tbl)$p.value, 4)
    cramV = round(cramersV(tbl), 4) 
    data.frame(x, y, chisq_pval, cramV) }

# create unique combinations of column names
# sorting will help getting a better plot (upper triangular)
df_comb = data.frame(t(combn(sort(names(df)), 2)), stringsAsFactors = F)

# apply function to each variable combination
df_res = map2_df(df_comb$X1, df_comb$X2, f)

# plot results
df_res %>%
  ggplot(aes(x,y,fill=chisq_pval))+
  geom_tile()+
  geom_text(aes(x,y,label=cramV), size=2)+
  scale_fill_gradient(low="red", high="yellow")+
  theme_classic()+
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

# Function to find mixed associations found at:
# https://stackoverflow.com/questions/52554336/plot-the-equivalent-of-correlation-matrix-for-factors-categorical-data-and-mi
# By AntoniosK on StackOverflow
```

#Multivariate Outliers
```{r}
num <- which(sapply(df,is.numeric))

res.mout <- Moutlier(df[,num],quantile=0.99,plot=F)
length(which(res.mout$md > res.mout$cutoff))
mout <- which(res.mout$md > res.mout$cutoff)
summary(df[mout, num]) #Summary of outliers
plot(res.mout$md, res.mout$rd)

#df <- df[-m.out,] #remove multivariate outliers
```
Maybe because there is continuity in the distribution we don't take them out (see plot)

#Profiling of target variable 
```{r}
summary(df$Churn)
ptt<-prop.table(table(df$Churn));ptt
catdes(df,21)
```


#Modelling

#Model with numerical variables

```{r}
attach(df)
nm1 <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, family="binomial", data = df)
summary(nm1)
vif.nm1 <- vif(nm1);vif.nm1
step(nm1,k= log(nrow(df))) 
```

```{r}
nm2 <- glm(Churn ~ tenure + MonthlyCharges, family="binomial", data = df)
summary(nm2)
anova(nm2,nm1,test="Chisq") #p-value: 0.02277 -> we reject at 95% confidence that the variance explained is the same. We don't at 99% confidence. 


```


#Transformations of numerical variables
Firstly, we examine marginalModelPlots to gain insights into which variables effectively fit the model. Subsequently, we observed the necessity for a transformation in the tenure variable.
A reduction of one unit in tenure is associated with a log-odds increase of -0.054850 for Churn. Consequently, implementing a Square Root Transformation becomes imperative.

```{r}
nm3 <- glm(Churn ~ tenure+ I(tenure^2) + MonthlyCharges, family="binomial", data = df)
summary(nm3)

library(car)
marginalModelPlots(nm3)

nm4 <- glm(Churn ~ poly(tenure,2) + MonthlyCharges, family="binomial", data = df)
summary(nm4)
marginalModelPlots(nm4)



```

#Adding main categorical effects
```{r}

```

#Interactions
```{r}

```

